{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "from keras.models import Model\n",
    "from l3embedding.model import load_model\n",
    "from l3embedding import vision_model, audio_model\n",
    "import gzip, bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/scratch/jtc440/openl3_models\"\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_gzip(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = f.read()\n",
    "        \n",
    "    with gzip.open(filepath + '.gz', 'w') as f:\n",
    "        f.write(data)\n",
    "        \n",
    "def compress_gzip(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = f.read()\n",
    "        \n",
    "    with gzip.open(filepath + '.gz', 'w') as f:\n",
    "        f.write(data)\n",
    "        \n",
    "def compress_bz2(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = f.read()\n",
    "            \n",
    "    with bz2.BZ2File(filepath + '.bz2', 'w') as f:\n",
    "        f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/beegfs/jtc440/miniconda3/envs/l3embedding-new/lib/python3.6/site-packages/librosa/filters.py:261: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n"
     ]
    }
   ],
   "source": [
    "weights_path = '/scratch/jtc440/l3_output/converted_models/embedding/music/cnn_L3_kapredbinputbn/20180905220149/model_best_valid_accuracy.h5'\n",
    "weights_path = '/scratch/jtc440/l3_output/converted_models/embedding/music/cnn_L3_melspec1/20180905154214/model_best_valid_accuracy.h5'\n",
    "weights_path = '/scratch/jtc440/l3_output/converted_models/embedding/music/cnn_L3_melspec2/20180906172059/model_best_valid_accuracy.h5'\n",
    "weights_path = '/scratch/jtc440/l3_output/converted_models/embedding/environmental/cnn_L3_kapredbinputbn/20180905221614/model_best_valid_accuracy.h5'\n",
    "weights_path = '/scratch/jtc440/l3_output/converted_models/embedding/environmental/cnn_L3_melspec1/20180905195208/model_best_valid_accuracy.h5'\n",
    "weights_path = '/scratch/jtc440/l3_output/converted_models/embedding/environmental/cnn_L3_melspec2/20180905191651/model_best_valid_accuracy.h5'\n",
    "\n",
    "\n",
    "model_type = weights_path.split('/')[7]\n",
    "\n",
    "if 'kapre' in weights_path:\n",
    "    input_repr = \"linear\"\n",
    "elif 'melspec1' in weights_path:\n",
    "    input_repr = \"mel128\"\n",
    "elif 'melspec2' in weights_path:\n",
    "    input_repr = \"mel256\"\n",
    "\n",
    "subset = weights_path.split('/')[6]\n",
    "if subset[0] == 'e':\n",
    "    subset = 'env'\n",
    "\n",
    "m, inputs, output = load_model(weights_path, model_type, return_io=True)                                     \n",
    "x_i, x_a = inputs\n",
    "image_model_output = m.get_layer('vision_model').get_layer('vision_embedding_layer').output\n",
    "audio_model_output = m.get_layer('audio_model').get_layer('audio_embedding_layer').output\n",
    "\n",
    "image_embed_model = Model(inputs=x_i, outputs=image_model_output)\n",
    "audio_embed_model = Model(inputs=x_a, outputs=audio_model_output)\n",
    "\n",
    "audio_output_path = os.path.join(output_dir, 'openl3_audio_{}_{}.h5'.format(input_repr, subset))\n",
    "image_output_path = os.path.join(output_dir, 'openl3_image_{}_{}.h5'.format(input_repr, subset))\n",
    "\n",
    "image_embed_model.save_weights(image_output_path)\n",
    "audio_embed_model.save_weights(audio_output_path)\n",
    "\n",
    "compress_gzip(image_output_path)\n",
    "compress_bz2(image_output_path)\n",
    "compress_gzip(audio_output_path)\n",
    "compress_bz2(audio_output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
